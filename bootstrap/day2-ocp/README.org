#+TITLE: Day-2 Operations on OKD/OCP

* Deployment...

* MetalLB deployment patches

The deployment needs special permissions in order to be deployed.

#+begin_example
$ oc new-project metallb-system
$ oc adm policy add-scc-to-user anyuid -z controller -n metallb-system
$ oc adm policy add-scc-to-user privileged -z speaker -n metallb-system
#+end_example

Run =kustomize= / =kubectl= command to apply MetalLB.

* Adding permissions to my user

  #+begin_example
  $ kubectl apply -f ./resources/add-permission-to-user.yaml
  #+end_example

  Login on https://console-openshift-console.apps.$cluster.$domain/

  On the username dropdown, click the "Copy login command" and paste the result
  in the console.

* Disabling the kubeadmin user or replacing the password

* Adding an additional IngressController for domain sharding

[[https://docs.openshift.com/container-platform/4.9/networking/configuring_ingress_cluster_traffic/configuring-ingress-cluster-traffic-ingress-controller.html#nw-ingress-sharding-namespace-labels_configuring-ingress-cluster-traffic-ingress-controller][Configuring Ingress Controller sharding by using namespace labels]]

TLDR: an additional IP address used solely for a secondary ingress controller, this way "public" traffic can never hit "private" endpoints.

I should also add network policies in Calico to ensure this behavior.

This requires MetalLB in order to to configure the secondary IngressController with a LoadBalancer type IP.

* Replacing the default certificate for the =default= _IngressController_ with a signed Let's Encrypt certificate

1. Deploy cert-manager from =k8s/cert-manager/overlays/prod=
2. Run =kubectl apply -f ./resources/okd-ingress-certificate.yaml=

* Adding an Alertmanager endpoint

See https://docs.openshift.com/container-platform/4.9/monitoring/managing-alerts.html#applying-custom-alertmanager-configuration_managing-alerts

** Installation guideline TLDR
1. Extract the current Alertmanager configuration
   #+begin_example
   $ oc -n openshift-monitoring get secret alertmanager-main --template='{{ index .data "alertmanager.yaml" }}' | base64 --decode > alertmanager.yaml
   #+end_example

2. Add the following YAML under each receivers in the configuration file, replacing the =$URL= variable with the webhook url
   #+begin_example
   global:
     slack_api_url: $URL
   receivers:
   - name: default
     slack_configs:
     - send_resolved: true
       channel: alertes
   #+end_example

3. Deploy
   #+begin_example
   $ oc -n openshift-monitoring create secret generic alertmanager-main --from-file=alertmanager.yaml --dry-run -o=yaml | cat 1>&2 | oc -n openshift-monitoring replace secret --filename=-
   #+end_example

* Overriding the default storage class

1. Replace the default StorageClass with the patch =storage-class.yaml=:
#+begin_example
$ oc replace --force -f ./resources/storage-class.yaml
#+end_example

2. Delete pvcs using this default storage class

* Disabling remote health reporting

See https://docs.openshift.com/container-platform/4.9/support/remote_health_monitoring/opting-out-of-remote-health-reporting.html#opting-out-remote-health-reporting

* Adding persistent storage to prometheus

See https://docs.okd.io/latest/monitoring/configuring-the-monitoring-stack.html#configuring-the-monitoring-stack_configuring-the-monitoring-stack

Apply the patch in =resources/prometheus-pvc.yaml=.
